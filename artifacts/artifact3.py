import torch
import torch.nn.functional as F
from transformers import GPT2LMHeadModel, GPT2Tokenizer
import numpy as np
import time

class DotProductRoutedLMHead:
    def __init__(self, model, k=5, threshold=-float("inf"), rerank=True):
        self.model = model
        self.device = model.device
        self.k = k
        self.threshold = threshold
        self.rerank = rerank

        self.weight = model.lm_head.weight.data.to(self.device)
        self.bias = model.lm_head.bias.data.to(self.device) if model.lm_head.bias is not None else None

    def predict(self, hidden_state):
        if hidden_state.dim() == 3:
            hidden_state = hidden_state[:, -1, :]  # [1, hidden_dim]

        scores = torch.matmul(self.weight, hidden_state.view(-1))
        if self.bias is not None:
            scores += self.bias

        topk_scores, topk_indices = torch.topk(scores, self.k)
        top_score = topk_scores[0].item()

        if top_score >= self.threshold:
            if self.rerank:
                probs = F.softmax(topk_scores, dim=-1)
                selected = torch.argmax(probs).item()
                return topk_indices[selected].unsqueeze(0), True, top_score
            else:
                return topk_indices[0].unsqueeze(0), True, top_score
        else:
            # Fallback (should rarely happen if threshold is calibrated well)
            logits = torch.matmul(self.weight, hidden_state.squeeze(0))
            if self.bias is not None:
                logits += self.bias
            return torch.argmax(logits).unsqueeze(0), False, top_score

class ThresholdTuner:
    def __init__(self, model_name="gpt2", k=5):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model = GPT2LMHeadModel.from_pretrained(model_name).to(self.device).eval()
        self.tokenizer = GPT2Tokenizer.from_pretrained(model_name)
        self.tokenizer.pad_token = self.tokenizer.eos_token
        self.k = k

    def calibrate_threshold(self, prompts, max_new_tokens=20, percentile=10):
        scores = []
        router = DotProductRoutedLMHead(self.model, k=self.k, threshold=-float("inf"))

        for prompt in prompts:
            input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids.to(self.device)
            past_key_values = None
            with torch.no_grad():
                for _ in range(max_new_tokens):
                    out = self.model.transformer(input_ids, past_key_values=past_key_values, use_cache=True)
                    hidden = out[0][:, -1:, :]
                    past_key_values = out[1]

                    _, _, score = router.predict(hidden)
                    scores.append(score)
                    input_ids = torch.argmax(self.model.lm_head(hidden), dim=-1).unsqueeze(0)

        threshold = np.percentile(scores, percentile)
        print(f"\nâœ… Calibrated routing threshold (P{percentile}): {threshold:.2f}")
        return threshold

    def evaluate(self, threshold, prompts, max_new_tokens=20):
        router = DotProductRoutedLMHead(self.model, k=self.k, threshold=threshold)
        total, correct, routed, score_log = 0, 0, 0, []

        for prompt in prompts:
            input_ids = self.tokenizer(prompt, return_tensors="pt").input_ids.to(self.device)
            past_key_values = None

            with torch.no_grad():
                for _ in range(max_new_tokens):
                    out = self.model.transformer(input_ids, past_key_values=past_key_values, use_cache=True)
                    hidden = out[0][:, -1:, :]
                    past_key_values = out[1]

                    pred_id, routed_flag, score = router.predict(hidden)
                    score_log.append(score)

                    full_logits = self.model.lm_head(hidden)
                    baseline = torch.argmax(full_logits, dim=-1).item()

                    if pred_id.item() == baseline:
                        correct += 1
                    if routed_flag:
                        routed += 1

                    input_ids = pred_id.unsqueeze(0)
                    total += 1

        accuracy = correct / total
        routing_ratio = routed / total
        return {
            "threshold": threshold,
            "accuracy": accuracy,
            "routing_ratio": routing_ratio,
            "scores": score_log
        }

    def auto_tune_threshold(self, prompts, max_new_tokens=20, percentiles=[0, 5, 10, 15, 20, 25]):
        print("ğŸ“Š Calibrating thresholds...")

        results = []
        for p in percentiles:
            threshold = self.calibrate_threshold(prompts, max_new_tokens, percentile=p)
            stats = self.evaluate(threshold, prompts, max_new_tokens)
            results.append(stats)
            print(f" - P{p:2}: acc={stats['accuracy']:.2%}, routed={stats['routing_ratio']:.2%}")

        valid = [r for r in results if r['accuracy'] >= 0.97]
        if not valid:
            print("\nâŒ No threshold achieved â‰¥97% accuracy.")
            return None

        best = max(valid, key=lambda r: r['routing_ratio'])
        print(f"\nğŸ Best Threshold: {best['threshold']:.2f}")
        print(f"   Accuracy:       {best['accuracy']:.2%}")
        print(f"   Routed Tokens:  {best['routing_ratio']:.2%}")
        return best

if __name__ == "__main__":
    tuner = ThresholdTuner("gpt2", k=1)
    prompts = [
        "The meaning of life is",
        "The quantum computer",
        "In a distant galaxy, a civilization",
        "The future of AI will depend on",
        "Once upon a time",
    ]

    best = tuner.auto_tune_threshold(prompts, max_new_tokens=50)


""" Output:
ğŸ“Š Calibrating thresholds...

âœ… Calibrated routing threshold (P0): -252.28
 - P 0: acc=100.00%, routed=100.00%

âœ… Calibrated routing threshold (P5): -227.59
 - P 5: acc=100.00%, routed=94.80%

âœ… Calibrated routing threshold (P10): -204.72
 - P10: acc=100.00%, routed=90.00%

âœ… Calibrated routing threshold (P15): -147.56
 - P15: acc=100.00%, routed=84.80%

âœ… Calibrated routing threshold (P20): -117.48
 - P20: acc=100.00%, routed=80.00%

âœ… Calibrated routing threshold (P25): -109.72
 - P25: acc=100.00%, routed=74.80%

ğŸ Best Threshold: -252.28
   Accuracy:       100.00%
   Routed Tokens:  100.00%
"""